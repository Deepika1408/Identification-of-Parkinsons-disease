# -*- coding: utf-8 -*-
"""CatBoost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KFWlfjXHXrbzYDyrOnFW2iVHYzNJZW0G

***CATBOOST***

---



---
"""

import numpy as np 
import pandas as pd

data = pd.read_csv("/content/pd_speech_features.csv")

data.head()

"""**Preprocessing of dataset**

---


"""

data.info

data.drop(['id'], axis=1)

data = data.drop_duplicates()
data = data.dropna()
data.info()

data.shape

data.columns

data.describe().transpose()

y=data.loc[:,'class']
x=data.iloc[:,-1]

x.head()

y.head()

for x in data.columns:
    data[x]= (data[x]-data[x].min())/(data[x].max()-data[x].min())
data.head()
y=data['class']
x=data.drop(['class'],axis=1)



"""**Univariate Analysis**

---


"""

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns 
import matplotlib.pyplot as plt 
# %matplotlib inline
fig, ax = plt.subplots(1,3,figsize=(16,10)) 
sns.boxplot(x='f1',data=data, ax=ax[0],orient='v') 
sns.boxplot(x='f2',data=data, ax=ax[1],orient='v') 
sns.boxplot(x='f3',data=data, ax=ax[1],orient='v') 
sns.boxplot(x='f4',data=data, ax=ax[1],orient='v') 
sns.boxplot(x='PPE',data=data,ax=ax[2],orient='v')

"""The above gure shows the box plot of the frequency variation. All the three variations have outliers. Generally speaking, decision trees are able to handle outliers. It is very unlikely that decision tree will create a leaf to isolate them"""

fig, ax = plt.subplots(1,3,figsize=(16,8)) 
sns.distplot(data['mean_MFCC_2nd_coef'],ax=ax[0]) 
sns.distplot(data[  'IMF_SNR_SEO'],ax=ax[1]) 
sns.distplot(data[  'GNE_NSR_SEO'],ax=ax[2])

"""The measures of vocal fundamental frequency are shown above"""

fig, ax = plt.subplots(2,3,figsize=(16,8)) 
sns.distplot(data['locShimmer'],ax=ax[0,0]) 
sns.distplot(data['apq11Shimmer'],ax=ax[0,1]) 
sns.distplot(data['locDbShimmer'],ax=ax[0,2]) 
sns.distplot(data['apq3Shimmer'],ax=ax[1,0]) 
sns.distplot(data['apq5Shimmer'],ax=ax[1,1]) 
sns.distplot(data['ddaShimmer'],ax=ax[1,2])

"""For all of the above graphs, we can observe that the measure of variation in amplitude is positively skewed"""

fig, ax = plt.subplots(1,2,figsize=(16,8))
sns.boxplot(x='class',y='DFA',data=data,ax=ax[0])
sns.boxplot(x='class',y='DFA',data=data,ax=ax[1])

# For categorical predictors
cols = ["locPctJitter","locAbsJitter","rapJitter","ppq5Jitter","ddpJitter"]
fig, axs = plt.subplots(ncols = 5,figsize=(16,8))
fig.tight_layout()
for i in range(0,len(cols)):
    sns.boxplot(x='class',y=cols[i],data=data, ax = axs[i])

"""People who are suffering for PD tend to have higher jitter %.  The variation of fundamental frequency is in a low range for people who is normal.

**Applying Model**

---
"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=32)

!pip install catboost

import gc
from catboost import CatBoostRegressor

cb_model = CatBoostRegressor(iterations=500,
                             learning_rate=0.05,
                             depth=10,
                             eval_metric='RMSE',
                             random_seed = 42,
                             bagging_temperature = 0.2,
                             od_type='Iter',
                             metric_period = 50,
                             od_wait=20)

cb_model.fit(X_train, y_train,
             eval_set=(X_test, y_test),
             use_best_model=True,
             verbose=50)

import math 
from sklearn.metrics import mean_squared_error, r2_score,accuracy_score 
y_predict= cb_model.predict(X_test)

#RMSE(root mean squared error)
Rmse_test = math.sqrt(mean_squared_error(y_test,y_predict))
#R2 Score
r2_test = r2_score(y_test,y_predict) 
print("Evaluation on test data")
#print("ACCURACY: {:.2f}".format(score)) 
print("RMSE: {:.2f}".format(Rmse_test)) 
print("R2: {:.2f}".format(r2_test))

"""Label Encoding

"""

y_predict=cb_model.predict(X_test)
y_predict=(y_predict>0.5).flatten().astype(int)
y_predict

"""**Accuracy**

---


"""

score=accuracy_score(y_predict,y_test)
print("Test Accuracy :",score*100)

n= X_train.shape[0] 
p= X_train.shape[1] 
adj_r2_test = 1-(1-r2_test)*(n-1)/(n-p-1) 
print("Adjusted R2: {:.2f}".format(adj_r2_test))

"""**Evaluation Metrics**

---


"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_predict)
cm

disp = ConfusionMatrixDisplay(confusion_matrix=cm) 
disp.plot()

from sklearn.metrics import precision_recall_curve
precision, recall, thresholds = precision_recall_curve(y_predict,y_test) 
print("Precision: ",precision) 
print("Recall: ",recall) 
print("Thresholds: ",thresholds)

import matplotlib.pyplot as plt 
fig, ax = plt.subplots()
ax.plot(recall, precision, color='purple')
#add axis labels to plot 
ax.set_title('Precision-Recall Curve') 
ax.set_ylabel('Precision') 
ax.set_xlabel('Recall')
#display plot
plt.show()

from sklearn.metrics import roc_auc_score 
print("ROC Accuracy score is: ",roc_auc_score(y,cb_model.predict_proba(x)[:, 1])*100,"%")